{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install face_recognition","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T07:24:18.248254Z","iopub.execute_input":"2025-06-12T07:24:18.248845Z","iopub.status.idle":"2025-06-12T07:24:42.692232Z","shell.execute_reply.started":"2025-06-12T07:24:18.248813Z","shell.execute_reply":"2025-06-12T07:24:42.691440Z"}},"outputs":[{"name":"stdout","text":"Collecting face_recognition\n  Downloading face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\nCollecting face-recognition-models>=0.3.0 (from face_recognition)\n  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (8.1.8)\nRequirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (19.24.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from face_recognition) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from face_recognition) (11.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->face_recognition) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->face_recognition) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->face_recognition) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->face_recognition) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->face_recognition) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->face_recognition) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->face_recognition) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->face_recognition) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->face_recognition) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->face_recognition) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->face_recognition) (2024.2.0)\nDownloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\nBuilding wheels for collected packages: face-recognition-models\n  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566166 sha256=eb9d31b01257dfff839fe4c9b8dee468cf35f036c5446cbc7c1c33e41e363895\n  Stored in directory: /root/.cache/pip/wheels/04/52/ec/9355da79c29f160b038a20c784db2803c2f9fa2c8a462c176a\nSuccessfully built face-recognition-models\nInstalling collected packages: face-recognition-models, face_recognition\nSuccessfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport face_recognition\nimport os\nfrom datetime import datetime\n\n# Path to the images directory\npath = '/kaggle/input/face-recognition-dataset/Faces/Faces/'\nimages = []\nclassNames = []\nmyList = os.listdir(path)\n\n# Importing images and extracting names\nfor cl in myList:\n    curImg = cv2.imread(f'{path}/{cl}')\n    images.append(curImg)\n    classNames.append(os.path.splitext(cl)[0])\n\n# Function to encode the images\ndef findEncodings(images):\n    encodeList = []\n    for img in images:\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        encode = face_recognition.face_encodings(img)[0]\n        encodeList.append(encode)\n    return encodeList\n\n# Function to mark attendance\ndef markAttendance(name):\n    with open('D:\\\\attendance.csv', 'r+' ) as f:\n        myDataList = f.readlines()\n        nameList = []\n        for line in myDataList:\n            entry = line.split(',')\n            nameList.append(entry[0])\n        if name not in nameList:\n            now = datetime.now()\n            dtString = now.strftime('%H:%M:%S')\n            f.writelines(f'\\n{name},{dtString}')\n\n# Encoding the images\nencodeListKnown = findEncodings(images)\nprint('Encoding Complete')\n\n# Starting webcam\ncap = cv2.VideoCapture(0)\n\nwhile True:\n    success, img = cap.read()\n    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n\n    faceCurFrame = face_recognition.face_locations(imgS)\n    encodeCurFrame = face_recognition.face_encodings(imgS, faceCurFrame)\n\n    # Matching found faces with known faces\n    for encodeFace, faceLoc in zip(encodeCurFrame, faceCurFrame):\n        matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n        faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n        matchIndex = np.argmin(faceDis)\n\n        if matches[matchIndex]:\n            name = classNames[matchIndex].upper()\n            y1, x2, y2, x1 = faceLoc\n            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n            cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED)\n            cv2.putText(img, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n            markAttendance(name)\n\n    cv2.imshow('Webcam', img)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T07:25:00.399248Z","iopub.execute_input":"2025-06-12T07:25:00.399532Z","iopub.status.idle":"2025-06-12T07:25:46.105023Z","shell.execute_reply.started":"2025-06-12T07:25:00.399505Z","shell.execute_reply":"2025-06-12T07:25:46.104142Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/1845293617.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Encoding the images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mencodeListKnown\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindEncodings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Encoding Complete'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/1845293617.py\u001b[0m in \u001b[0;36mfindEncodings\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_encodings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mencodeList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mencodeList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"],"ename":"IndexError","evalue":"list index out of range","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}